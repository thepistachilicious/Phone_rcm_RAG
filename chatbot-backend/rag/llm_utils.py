# rag/llm_utils.py
import os
import json
from dotenv import load_dotenv
import google.generativeai as genai
import re

load_dotenv()
gemini_api_key = os.getenv("GEMINI_API_KEY")
genai.configure(api_key=gemini_api_key)


def analyze_query_with_gemini(query: str, history_context: str) -> dict:
    prompt = f"""
    L·ªãch s·ª≠ h·ªôi tho·∫°i:
    {history_context}

    C√¢u h·ªèi m·ªõi: "{query}"

    Ph√¢n t√≠ch:
    1. C√¢u h·ªèi c√≥ m∆° h·ªì kh√¥ng v√† c·∫ßn ƒë∆∞·ª£c l√†m r√µ d·ª±a tr√™n l·ªãch s·ª≠ h·ªôi tho·∫°i kh√¥ng? (true/false)
    2. C√¢u h·ªèi ƒë√£ ƒë∆∞·ª£c tr·∫£ l·ªùi tr∆∞·ªõc ƒë√≥ trong l·ªãch s·ª≠ ch∆∞a? (true/false)
    3. N·∫øu ƒë√£ tr·∫£ l·ªùi, tr√≠ch xu·∫•t c√¢u tr·∫£ l·ªùi t·ª´ l·ªãch s·ª≠.
    4. N·∫øu m∆° h·ªì v√¨ li√™n quan ƒë·∫øn l·ªãch s·ª≠, vi·∫øt l·∫°i c√¢u h·ªèi cho r√µ r√†ng, kh√¥ng th√™m th√¥ng tin m·ªõi.

    Tr·∫£ l·ªùi theo ƒë·ªãnh d·∫°ng JSON:
    {{
      "is_ambiguous": True/False,
      "is_duplicate": True/False,
      "answered": "n·ªôi dung c√¢u tr·∫£ l·ªùi ho·∫∑c r·ªóng",
      "clarified_query": "c√¢u h·ªèi r√µ r√†ng ho·∫∑c r·ªóng"
    }}
    """

    try:
        model = genai.GenerativeModel("models/gemini-1.5-flash")
        response = model.generate_content(prompt)
        raw_text = response.text.strip()
        # Lo·∫°i b·ªè d·∫•u ```json v√† ```
        cleaned_response = re.sub(r"^```json|```$", "", raw_text.strip(), flags=re.MULTILINE).strip()

        print("üéØ Ph·∫£n h·ªìi t·ª´ Gemini:", cleaned_response)  # Debug
        try:
            result = json.loads(cleaned_response)
        except json.JSONDecodeError as json_err:
            print("L·ªói ph√¢n t√≠ch JSON:", json_err)
            raise ValueError("Ph·∫£n h·ªìi kh√¥ng ·ªü ƒë·ªãnh d·∫°ng JSON h·ª£p l·ªá.")

    except Exception as e:
        print("L·ªói khi ph√¢n t√≠ch ph·∫£n h·ªìi t·ª´ Gemini:", e)
        result = {
            "is_ambiguous": False,
            "is_duplicate": False,
            "answered": "",
            "clarified_query": query
        }
    return result

